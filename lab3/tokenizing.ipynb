{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenizing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fanny/information-retrieval/blob/master/lab3/tokenizing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cMSr_9Msq3AV",
        "colab_type": "code",
        "outputId": "1de7495b-2bbd-4023-86fb-28c36f9c6ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/fanny/information-retrieval/master/lab2/data/results.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>section</th>\n",
              "      <th>sub_title</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>05/04/2019 |</td>\n",
              "      <td>agronegocio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\t\\t\\t\\t</td>\n",
              "      <td>https://www.gazetadopovo.com.br/agronegocio/ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wiseup-news</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.gazetadopovo.com.br/wiseup-news/bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>futebol</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://especiais.gazetadopovo.com.br/futebol/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>05/04/2019 |</td>\n",
              "      <td>agronegocio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Suspensão de frigoríficos não impediu alta de ...</td>\n",
              "      <td>https://www.gazetadopovo.com.br/agronegocio/ag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>The Daily Signal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ideias</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pessoas que buscam uma identidade transsexual ...</td>\n",
              "      <td>Populares</td>\n",
              "      <td>https://www.gazetadopovo.com.br/ideias/nao-se-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Gazeta do Povo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>curitiba</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Depois de uma semana de calor, Curitiba terá u...</td>\n",
              "      <td>Populares</td>\n",
              "      <td>https://www.gazetadopovo.com.br/curitiba/previ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40</td>\n",
              "      <td>Flávia Alves, especial para a Gazeta do Povo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>viver-bem</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As promessas são muitas: combater o envelhecim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.gazetadopovo.com.br/viver-bem/saud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>Agência Estado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>republica</td>\n",
              "      <td>NaN</td>\n",
              "      <td>O líder do MDB na Câmara, Baleia Rossi (SP), p...</td>\n",
              "      <td>Populares</td>\n",
              "      <td>https://www.gazetadopovo.com.br/republica/pec-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>Daniel Malucelli</td>\n",
              "      <td>[05/04/2019]</td>\n",
              "      <td>esportes</td>\n",
              "      <td>mercado</td>\n",
              "      <td>O meia-atacante Maicosuel está com a situação ...</td>\n",
              "      <td>Paraná não descarta dispensa de Maicosuel ante...</td>\n",
              "      <td>https://www.gazetadopovo.com.br/esportes/paran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Renyere Trovão</td>\n",
              "      <td>NaN</td>\n",
              "      <td>automoveis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Concretizar a compra de um carro novo nem semp...</td>\n",
              "      <td>Populares</td>\n",
              "      <td>https://www.gazetadopovo.com.br/automoveis/car...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   _id                                        author          date  \\\n",
              "0    7                                           NaN  05/04/2019 |   \n",
              "1    2                                           NaN           NaN   \n",
              "2    3                                           NaN           NaN   \n",
              "3    9                                           NaN  05/04/2019 |   \n",
              "4    1                              The Daily Signal           NaN   \n",
              "5    5                                Gazeta do Povo           NaN   \n",
              "6   40  Flávia Alves, especial para a Gazeta do Povo           NaN   \n",
              "7    6                                Agência Estado           NaN   \n",
              "8   20                              Daniel Malucelli  [05/04/2019]   \n",
              "9   10                                Renyere Trovão           NaN   \n",
              "\n",
              "       section sub_title                                               text  \\\n",
              "0  agronegocio       NaN                                                NaN   \n",
              "1  wiseup-news       NaN                                                NaN   \n",
              "2      futebol       NaN                                                NaN   \n",
              "3  agronegocio       NaN                                                NaN   \n",
              "4       ideias       NaN  Pessoas que buscam uma identidade transsexual ...   \n",
              "5     curitiba       NaN  Depois de uma semana de calor, Curitiba terá u...   \n",
              "6    viver-bem       NaN  As promessas são muitas: combater o envelhecim...   \n",
              "7    republica       NaN  O líder do MDB na Câmara, Baleia Rossi (SP), p...   \n",
              "8     esportes   mercado  O meia-atacante Maicosuel está com a situação ...   \n",
              "9   automoveis       NaN  Concretizar a compra de um carro novo nem semp...   \n",
              "\n",
              "                                               title  \\\n",
              "0                                           \\t\\t\\t\\t   \n",
              "1                                                NaN   \n",
              "2                                                NaN   \n",
              "3  Suspensão de frigoríficos não impediu alta de ...   \n",
              "4                                          Populares   \n",
              "5                                          Populares   \n",
              "6                                                NaN   \n",
              "7                                          Populares   \n",
              "8  Paraná não descarta dispensa de Maicosuel ante...   \n",
              "9                                          Populares   \n",
              "\n",
              "                                                 url  \n",
              "0  https://www.gazetadopovo.com.br/agronegocio/ex...  \n",
              "1  https://www.gazetadopovo.com.br/wiseup-news/bo...  \n",
              "2  https://especiais.gazetadopovo.com.br/futebol/...  \n",
              "3  https://www.gazetadopovo.com.br/agronegocio/ag...  \n",
              "4  https://www.gazetadopovo.com.br/ideias/nao-se-...  \n",
              "5  https://www.gazetadopovo.com.br/curitiba/previ...  \n",
              "6  https://www.gazetadopovo.com.br/viver-bem/saud...  \n",
              "7  https://www.gazetadopovo.com.br/republica/pec-...  \n",
              "8  https://www.gazetadopovo.com.br/esportes/paran...  \n",
              "9  https://www.gazetadopovo.com.br/automoveis/car...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "KpMuYE5nu0eh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_text = data['text'].dropna()\n",
        "def filter_by_criteria(text, criteria):\n",
        "  filtered_words = re.findall(criteria, text)\n",
        "  filtered_words = ' '.join(filtered_words)\n",
        " \n",
        "  return filtered_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjNZ_NowuNv3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_words_filtered(criteria):\n",
        "  filtered_text = clean_text.apply(lambda text: filter_by_criteria(text, criteria))\n",
        "  all_filtered_text = filtered_text.str.cat(sep=' ')\n",
        "  all_words_filtered = all_filtered_text.split(' ')\n",
        "\n",
        "  all_words_filtered = [text for text in all_words_filtered if len(text) > 0]\n",
        "\n",
        "  return set(all_words_filtered[:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-ndzfdMrLAY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenização\n",
        "\n",
        "> Tokenização é o processo de formar palavras de uma sequência de caracteres em um documento    \n",
        "\n",
        "**Obs: Texto extraido do livro**\n",
        "\n",
        "E para formar essas palavras podemos usar alguns critérios, como:\n",
        "- Quantidade de caracteres; Palavras hifenizadas; Caracteres especiais;\n",
        "- Caracteres em Caixa Alta ou Baixa; Apostrófos; Números; Abreviações;\n",
        "\n",
        "Cada critério desse, pode guardar uma importância, se tratando dessa base de dados de notícias, alguns poderão ser mais relevantes que outros e veremos o motivo.\n",
        "\n",
        "Para conseguir concluir quais critérios usar no processo de tokenização, começaremos analisando os dados, garantindo assim que não ignoremos palavras que são importantes.\n",
        "\n",
        "Se você quiser pular essa parte de análise, e ir para os critérios de tokenização que irei considerar, [clique aqui](https://colab.research.google.com/drive/1EP_hx0xDOgID34aTHwCNL-AFgBWvrGcH?authuser=1#scrollTo=hz-6d5cp6zEJ), mas tenha em mente que só explico os fatores que me levaram a tomar essa decisão aqui embaixo.\n",
        "\n",
        "### Quantidade de caracteres\n",
        "\n",
        "A primeira suposição é que palavras com quantidade menores que 3 geralmente não são importantes, porque representam artigos, preposições etc, que não agregam tanto valor na busca.\n",
        "\n",
        "#### Resultados"
      ]
    },
    {
      "metadata": {
        "id": "KFMDH8RCvwos",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_words_filtered(r'\\b\\w{0,3}\\b')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-o0_tBawkOR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A título de informação, só mostramos o set das 200 primeiras, mas olhando os dados podemos observar coisas interessantes como:\n",
        "\n",
        "- Palavras capitalizadas indicam Siglas - APA, PIB, IPI, IVA, PEC, RJ\n",
        "- Números só com um dígito, não são relevantes\n",
        "- Ocorrem palavras com tamanho menor ou igual a dois que são importantes, indicam siglas, como 'RJ', 'PEC' e outras que o seu próprio significado tem muito valor, como 'gay' e 'pai'\n",
        "\n",
        "Sendo assim, removeremos as palavras de tamanho 1 e as stopwords do brasil.\n"
      ]
    },
    {
      "metadata": {
        "id": "rNxdCiesybQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Palavras hífenizadas\n",
        "\n",
        "Provavelmente palavras com hífen serão muito importantes, porque elas representam dias da semana, nomes geográficos(Grã-Bretanha), certas espécies de animais e vegetais(Bem-te-vi, Couve-Flor) alguns adjetivos (mal-humorada) dentre outras."
      ]
    },
    {
      "metadata": {
        "id": "rOejJ_Uoyv0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_words_filtered(r'[a-zA-Z]+\\-[a-zA-Z]+')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8NjwunyzIQW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "De fato, foram encontrados dias da semana, partidos, cargos, e muitas palavras importantes com hífen demonstrando que elas não devem ser removidas.\n",
        "\n",
        "### Caracteres especiais\n",
        "\n",
        "Também podem ser importantes, basta pensarmos em '%' que pode indicar percentuais, '$' que pode indicar dinheiro, 'º' que pode inficar uma posição, enfim, veremos a seguir, se esses símbolos são importantes no texto.\n",
        "\n",
        "Olhando símbolos nos textos, além da nossa suposição, foram encontrados certos delimitadores, que não acrescentam informações no texto como:\n",
        "- '\\r\\n'\n",
        "- '\\xaO'  \n",
        "Sendo assim, removeremos eles.\n",
        "\n",
        "### Apóstrofos\n",
        "\n",
        "Podem indicar marcas (Burguer’s King, McDonald’s) extrangeiras, ou uma “composição” de palavras como: pingo d’ água\n",
        "\n",
        "#### Resultados"
      ]
    },
    {
      "metadata": {
        "id": "6olTKbvP4_6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_words_filtered(r\"\\w+\\'\\w*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xTY0I-fr5Qfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As palavras encontradas com apóstrofo,  provavlmente são erros de digitação/formatação, fazendo mais sentido da replace pra um caractere vazio, e não considerar o hífen na tokenização.\n",
        "\n",
        "### Números\n",
        "\n",
        "Números são extremamente importantes, podem indicar horas, salários, anos, posições, temperaturas, etc.\n",
        "\n",
        "#### Resultados\n"
      ]
    },
    {
      "metadata": {
        "id": "6xDTf4tG50zT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_words_filtered(r'\\d+\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_XRkZz65_xe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Confirmando a suposição, não é interessante removê-los.\n",
        "\n",
        "### Abreviações\n",
        "\n",
        "Podem agregar muito valor pois servem para indicar cidades, siglas e etc..\n",
        "\n",
        "### Resultados"
      ]
    },
    {
      "metadata": {
        "id": "EZlRNDrg6p_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_words_filtered(r'(\\w+\\.\\w+)*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hz-6d5cp6zEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assim, como no caso anterior, não é bom que eliminemos, pois temos números decimais, domínios de sites e etc.\n",
        "\n",
        "## Conlusões dos critérios de tokenização\n",
        "\n",
        "Da análise anterior, fica claro, que removeremos apóstrofos, palavras de tamanho igual a 1, stopwords e alguns símbolos de escape.\n",
        "\n",
        "## Criando os tokens\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UxXlEInnOUEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Entendendo regex\n",
        "\n",
        "\n",
        "\n",
        "```regex\n",
        "\\w{2,}[\\-*|\\.*]\\w+|\\d{2,}[\\.*|\\,*]\\d+|\\w{2,}|\\d{2,}'\n",
        "\n",
        "```\n",
        "Quebramos em tokens pelos seguintes critérios:\n",
        "- Palavras com tamanho maior que 2: `\\w{2,}`\n",
        "- Números com quant. de algarismos maior que 2 com símbolos: `\\w?\\W*\\d{2,}\\W*`\n",
        "- Palavras hifenizadas, ou com ponto:`\\w{2,}[\\-*|\\.*]\\w+`\n",
        "- Números decimais com símbolos('$', '%'): `\\w?\\d{2,}[\\.|\\,]*\\d+\\W*`"
      ]
    },
    {
      "metadata": {
        "id": "JiZtEVa2DgSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('portuguese'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDmyNhHaFPbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text = clean_text.str.cat(sep=' ')\n",
        "\n",
        "hyphenated_and_abreviated_words = '\\w{2,}[\\-|\\.]*\\w+'\n",
        "decimal_numbers_with_symbols = '\\w?\\W?\\d{2,}[\\.|\\,]*\\d+\\W?'\n",
        "words ='\\w{2,}'\n",
        "numbers_with_symbols = '\\w?\\W?\\d{2,}\\W?'\n",
        "\n",
        "\n",
        "word_list = regexp_tokenize(all_text, pattern='%s|%s|%s|%s' %(hyphenated_and_abreviated_words, decimal_numbers_with_symbols, words, numbers_with_symbols))\n",
        "word_list = pd.Series(word_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgYN9L1eC_b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "52584882-57f7-4b1d-b75d-3df560ae2791"
      },
      "cell_type": "code",
      "source": [
        "word_list_whithout_stopwords = word_list[~word_list.isin(stopwords)]\n",
        "word_list_whithout_stopwords = pd.DataFrame(word_list_whithout_stopwords, columns=['word'])\n",
        "unique_words_whithout_stopwords = word_list_whithout_stopwords['word'].unique()\n",
        "word_list_whithout_stopwords.head(30)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pessoas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>buscam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>identidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>transsexual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nasceram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>assim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>crianças</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>devem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>estimuladas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>fazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>transição</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>sexo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>oposto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Quem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>diz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>obra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>referência</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>recomendada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Associação</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Norte-Americana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Psicologia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>APA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>sigla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>inglês</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ainda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>assim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>todos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>dias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>ouço</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               word\n",
              "0           Pessoas\n",
              "2            buscam\n",
              "4        identidade\n",
              "5       transsexual\n",
              "7          nasceram\n",
              "8             assim\n",
              "9          crianças\n",
              "11            devem\n",
              "12              ser\n",
              "13      estimuladas\n",
              "14            fazer\n",
              "15        transição\n",
              "17             sexo\n",
              "18           oposto\n",
              "19             Quem\n",
              "20              diz\n",
              "22             obra\n",
              "24       referência\n",
              "25      recomendada\n",
              "27       Associação\n",
              "28  Norte-Americana\n",
              "30       Psicologia\n",
              "31              APA\n",
              "33            sigla\n",
              "35           inglês\n",
              "36            Ainda\n",
              "37            assim\n",
              "38            todos\n",
              "40             dias\n",
              "41             ouço"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "dLoBPPSlBqsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_percentage(value):\n",
        "  return value * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdY8vWWkCZCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d89ba69c-7e2e-42b3-8e73-57de45bf2668"
      },
      "cell_type": "code",
      "source": [
        "frequencies = word_list_whithout_stopwords['word'].value_counts()\n",
        "relative_frequencies = word_list_whithout_stopwords['word'].value_counts(normalize=True)\n",
        "relative_frequencies = relative_frequencies.apply(get_percentage)\n",
        "\n",
        "relative_frequencies.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ser           0.447225\n",
              "disse         0.421750\n",
              "sobre         0.393444\n",
              "governo       0.390614\n",
              "anos          0.382122\n",
              "Brasil        0.294376\n",
              "presidente    0.280223\n",
              "Em            0.280223\n",
              "pode          0.274562\n",
              "ainda         0.271731\n",
              "Name: word, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "KU4qHLsGCfa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1618
        },
        "outputId": "f4c02650-908e-4aba-8888-d6197a1c8429"
      },
      "cell_type": "code",
      "source": [
        "ranking = np.arange(1,len(unique_words_whithout_stopwords)+1)\n",
        "\n",
        "most_frequent_words = {\n",
        "    'frequency': frequencies,\n",
        "    'r': ranking,\n",
        "    'Pr(%)': relative_frequencies,\n",
        "    'r.Pr': relative_frequencies * ranking\n",
        "}\n",
        "\n",
        "most_frequent_words = pd.DataFrame(most_frequent_words)\n",
        "most_frequent_words.head(50)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>r</th>\n",
              "      <th>Pr(%)</th>\n",
              "      <th>r.Pr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ser</th>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>0.447225</td>\n",
              "      <td>0.447225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disse</th>\n",
              "      <td>149</td>\n",
              "      <td>2</td>\n",
              "      <td>0.421750</td>\n",
              "      <td>0.843500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sobre</th>\n",
              "      <td>139</td>\n",
              "      <td>3</td>\n",
              "      <td>0.393444</td>\n",
              "      <td>1.180333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>governo</th>\n",
              "      <td>138</td>\n",
              "      <td>4</td>\n",
              "      <td>0.390614</td>\n",
              "      <td>1.562456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anos</th>\n",
              "      <td>135</td>\n",
              "      <td>5</td>\n",
              "      <td>0.382122</td>\n",
              "      <td>1.910612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Brasil</th>\n",
              "      <td>104</td>\n",
              "      <td>6</td>\n",
              "      <td>0.294376</td>\n",
              "      <td>1.766254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>presidente</th>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>0.280223</td>\n",
              "      <td>1.961561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Em</th>\n",
              "      <td>99</td>\n",
              "      <td>8</td>\n",
              "      <td>0.280223</td>\n",
              "      <td>2.241784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pode</th>\n",
              "      <td>97</td>\n",
              "      <td>9</td>\n",
              "      <td>0.274562</td>\n",
              "      <td>2.471058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ainda</th>\n",
              "      <td>96</td>\n",
              "      <td>10</td>\n",
              "      <td>0.271731</td>\n",
              "      <td>2.717314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ministro</th>\n",
              "      <td>85</td>\n",
              "      <td>11</td>\n",
              "      <td>0.240596</td>\n",
              "      <td>2.646551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bolsonaro</th>\n",
              "      <td>82</td>\n",
              "      <td>12</td>\n",
              "      <td>0.232104</td>\n",
              "      <td>2.785247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ano</th>\n",
              "      <td>82</td>\n",
              "      <td>13</td>\n",
              "      <td>0.232104</td>\n",
              "      <td>3.017351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pessoas</th>\n",
              "      <td>75</td>\n",
              "      <td>14</td>\n",
              "      <td>0.212290</td>\n",
              "      <td>2.972063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No</th>\n",
              "      <td>72</td>\n",
              "      <td>15</td>\n",
              "      <td>0.203799</td>\n",
              "      <td>3.056979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Os</th>\n",
              "      <td>72</td>\n",
              "      <td>16</td>\n",
              "      <td>0.203799</td>\n",
              "      <td>3.260777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>país</th>\n",
              "      <td>70</td>\n",
              "      <td>17</td>\n",
              "      <td>0.198138</td>\n",
              "      <td>3.368338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ter</th>\n",
              "      <td>70</td>\n",
              "      <td>18</td>\n",
              "      <td>0.198138</td>\n",
              "      <td>3.566475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Para</th>\n",
              "      <td>65</td>\n",
              "      <td>19</td>\n",
              "      <td>0.183985</td>\n",
              "      <td>3.495712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vai</th>\n",
              "      <td>64</td>\n",
              "      <td>20</td>\n",
              "      <td>0.181154</td>\n",
              "      <td>3.623086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Não</th>\n",
              "      <td>62</td>\n",
              "      <td>21</td>\n",
              "      <td>0.175493</td>\n",
              "      <td>3.685358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sistema</th>\n",
              "      <td>61</td>\n",
              "      <td>22</td>\n",
              "      <td>0.172663</td>\n",
              "      <td>3.798579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>após</th>\n",
              "      <td>59</td>\n",
              "      <td>23</td>\n",
              "      <td>0.167002</td>\n",
              "      <td>3.841037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na</th>\n",
              "      <td>58</td>\n",
              "      <td>24</td>\n",
              "      <td>0.164171</td>\n",
              "      <td>3.940106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Segundo</th>\n",
              "      <td>57</td>\n",
              "      <td>25</td>\n",
              "      <td>0.161341</td>\n",
              "      <td>4.033514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caso</th>\n",
              "      <td>55</td>\n",
              "      <td>26</td>\n",
              "      <td>0.155679</td>\n",
              "      <td>4.047666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>segundo</th>\n",
              "      <td>54</td>\n",
              "      <td>27</td>\n",
              "      <td>0.152849</td>\n",
              "      <td>4.126921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contra</th>\n",
              "      <td>52</td>\n",
              "      <td>28</td>\n",
              "      <td>0.147188</td>\n",
              "      <td>4.121260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bem</th>\n",
              "      <td>52</td>\n",
              "      <td>29</td>\n",
              "      <td>0.147188</td>\n",
              "      <td>4.268448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dois</th>\n",
              "      <td>51</td>\n",
              "      <td>30</td>\n",
              "      <td>0.144357</td>\n",
              "      <td>4.330720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maior</th>\n",
              "      <td>50</td>\n",
              "      <td>31</td>\n",
              "      <td>0.141527</td>\n",
              "      <td>4.387331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afirmou</th>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>0.141527</td>\n",
              "      <td>4.528857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grupo</th>\n",
              "      <td>48</td>\n",
              "      <td>33</td>\n",
              "      <td>0.135866</td>\n",
              "      <td>4.483569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mas</th>\n",
              "      <td>48</td>\n",
              "      <td>34</td>\n",
              "      <td>0.135866</td>\n",
              "      <td>4.619434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>todos</th>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>0.135866</td>\n",
              "      <td>4.755300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apenas</th>\n",
              "      <td>47</td>\n",
              "      <td>36</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>4.789267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acordo</th>\n",
              "      <td>47</td>\n",
              "      <td>37</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>4.922302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paulo</th>\n",
              "      <td>47</td>\n",
              "      <td>38</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>5.055337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>três</th>\n",
              "      <td>47</td>\n",
              "      <td>39</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>5.188372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>política</th>\n",
              "      <td>47</td>\n",
              "      <td>40</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>5.321407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>empresa</th>\n",
              "      <td>47</td>\n",
              "      <td>41</td>\n",
              "      <td>0.133035</td>\n",
              "      <td>5.454443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>outros</th>\n",
              "      <td>46</td>\n",
              "      <td>42</td>\n",
              "      <td>0.130205</td>\n",
              "      <td>5.468595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diz</th>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>0.130205</td>\n",
              "      <td>5.598800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poder</th>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>0.127374</td>\n",
              "      <td>5.604461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parte</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>0.127374</td>\n",
              "      <td>5.731835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia</th>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>0.127374</td>\n",
              "      <td>5.859209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ele</th>\n",
              "      <td>45</td>\n",
              "      <td>47</td>\n",
              "      <td>0.127374</td>\n",
              "      <td>5.986583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>empresas</th>\n",
              "      <td>45</td>\n",
              "      <td>48</td>\n",
              "      <td>0.127374</td>\n",
              "      <td>6.113957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>As</th>\n",
              "      <td>44</td>\n",
              "      <td>49</td>\n",
              "      <td>0.124544</td>\n",
              "      <td>6.102635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fim</th>\n",
              "      <td>43</td>\n",
              "      <td>50</td>\n",
              "      <td>0.121713</td>\n",
              "      <td>6.085652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            frequency   r     Pr(%)      r.Pr\n",
              "ser               158   1  0.447225  0.447225\n",
              "disse             149   2  0.421750  0.843500\n",
              "sobre             139   3  0.393444  1.180333\n",
              "governo           138   4  0.390614  1.562456\n",
              "anos              135   5  0.382122  1.910612\n",
              "Brasil            104   6  0.294376  1.766254\n",
              "presidente         99   7  0.280223  1.961561\n",
              "Em                 99   8  0.280223  2.241784\n",
              "pode               97   9  0.274562  2.471058\n",
              "ainda              96  10  0.271731  2.717314\n",
              "ministro           85  11  0.240596  2.646551\n",
              "Bolsonaro          82  12  0.232104  2.785247\n",
              "ano                82  13  0.232104  3.017351\n",
              "pessoas            75  14  0.212290  2.972063\n",
              "No                 72  15  0.203799  3.056979\n",
              "Os                 72  16  0.203799  3.260777\n",
              "país               70  17  0.198138  3.368338\n",
              "ter                70  18  0.198138  3.566475\n",
              "Para               65  19  0.183985  3.495712\n",
              "vai                64  20  0.181154  3.623086\n",
              "Não                62  21  0.175493  3.685358\n",
              "sistema            61  22  0.172663  3.798579\n",
              "após               59  23  0.167002  3.841037\n",
              "Na                 58  24  0.164171  3.940106\n",
              "Segundo            57  25  0.161341  4.033514\n",
              "caso               55  26  0.155679  4.047666\n",
              "segundo            54  27  0.152849  4.126921\n",
              "contra             52  28  0.147188  4.121260\n",
              "bem                52  29  0.147188  4.268448\n",
              "dois               51  30  0.144357  4.330720\n",
              "maior              50  31  0.141527  4.387331\n",
              "afirmou            50  32  0.141527  4.528857\n",
              "grupo              48  33  0.135866  4.483569\n",
              "Mas                48  34  0.135866  4.619434\n",
              "todos              48  35  0.135866  4.755300\n",
              "apenas             47  36  0.133035  4.789267\n",
              "acordo             47  37  0.133035  4.922302\n",
              "Paulo              47  38  0.133035  5.055337\n",
              "três               47  39  0.133035  5.188372\n",
              "política           47  40  0.133035  5.321407\n",
              "empresa            47  41  0.133035  5.454443\n",
              "outros             46  42  0.130205  5.468595\n",
              "diz                46  43  0.130205  5.598800\n",
              "poder              45  44  0.127374  5.604461\n",
              "parte              45  45  0.127374  5.731835\n",
              "dia                45  46  0.127374  5.859209\n",
              "Ele                45  47  0.127374  5.986583\n",
              "empresas           45  48  0.127374  6.113957\n",
              "As                 44  49  0.124544  6.102635\n",
              "fim                43  50  0.121713  6.085652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "gK6cJiu5HEbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Stemming"
      ]
    },
    {
      "metadata": {
        "id": "CJpijMzRHfzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "st = RSLPStemmer()\n",
        "  \n",
        "def to_stem_tokens(token):\n",
        "  return [token, st.stem(token)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIF4TMVnIlEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "aec279a1-7ce8-40ff-a030-4b7c488b862a"
      },
      "cell_type": "code",
      "source": [
        "stemming_tokens = word_list_whithout_stopwords['word'].apply(to_stem_tokens).tolist()\n",
        "stemming_tokens = pd.DataFrame(stemming_tokens, columns=['token', 'stem_token']) \n",
        "stemming_tokens.head(30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stem_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pessoas</td>\n",
              "      <td>pesso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buscam</td>\n",
              "      <td>busc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>identidade</td>\n",
              "      <td>ident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>transsexual</td>\n",
              "      <td>transsex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nasceram</td>\n",
              "      <td>nasc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>assim</td>\n",
              "      <td>assim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>crianças</td>\n",
              "      <td>crianç</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>devem</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ser</td>\n",
              "      <td>ser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>estimuladas</td>\n",
              "      <td>estimul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>fazer</td>\n",
              "      <td>faz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>transição</td>\n",
              "      <td>trans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>sexo</td>\n",
              "      <td>sex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>oposto</td>\n",
              "      <td>opost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Quem</td>\n",
              "      <td>qu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>diz</td>\n",
              "      <td>diz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>obra</td>\n",
              "      <td>obr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>referência</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>recomendada</td>\n",
              "      <td>recomend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Associação</td>\n",
              "      <td>associ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Norte-Americana</td>\n",
              "      <td>norte-americ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Psicologia</td>\n",
              "      <td>psicolog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>APA</td>\n",
              "      <td>apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>sigla</td>\n",
              "      <td>sigl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>inglês</td>\n",
              "      <td>ingl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Ainda</td>\n",
              "      <td>aind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>assim</td>\n",
              "      <td>assim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>todos</td>\n",
              "      <td>tod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>dias</td>\n",
              "      <td>dia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ouço</td>\n",
              "      <td>ouç</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              token    stem_token\n",
              "0           Pessoas         pesso\n",
              "1            buscam          busc\n",
              "2        identidade         ident\n",
              "3       transsexual      transsex\n",
              "4          nasceram          nasc\n",
              "5             assim         assim\n",
              "6          crianças        crianç\n",
              "7             devem           dev\n",
              "8               ser           ser\n",
              "9       estimuladas       estimul\n",
              "10            fazer           faz\n",
              "11        transição         trans\n",
              "12             sexo           sex\n",
              "13           oposto         opost\n",
              "14             Quem            qu\n",
              "15              diz           diz\n",
              "16             obra           obr\n",
              "17       referência         refer\n",
              "18      recomendada      recomend\n",
              "19       Associação        associ\n",
              "20  Norte-Americana  norte-americ\n",
              "21       Psicologia      psicolog\n",
              "22              APA           apa\n",
              "23            sigla          sigl\n",
              "24           inglês          ingl\n",
              "25            Ainda          aind\n",
              "26            assim         assim\n",
              "27            todos           tod\n",
              "28             dias           dia\n",
              "29             ouço           ouç"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "BMdUgxeDkc3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_group_by_stems = stemming_tokens.groupby('stem_token')\n",
        "for name_of_the_group, group in tokens_group_by_stems:\n",
        "  print(name_of_the_group)\n",
        "  print(group)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6x_2BLkIKfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Good, the Bad and the Ugly\n",
        "\n",
        "**Falsos Positivos Encontrados**:\n",
        "\n",
        "|id | stem_token | tokens  |  amiss  |\n",
        "| :---: | :---: |  :---:  |   :---:  | \n",
        "| 1. | gen | [genial, genes]  |  genial  | \n",
        "| 2. | ele | [eleições, eles]  |  eleições  |   \n",
        "| 3. | far | [farei, faria, fará, farinha]  | farinha |\n",
        "| 4. | nov | [novas, novo, nova, novamente]  |  novamente  |   \n",
        "| 5. | natur | [naturais, natureza, naturalizado]  |  naturalizado  |    \n",
        "| 6. | mão | [mães, mão]  |  mães | \n",
        "| 7. | mus | [musas, museu]  |  musas  |\n",
        "| 8. | mult | [multas, multidões]  |  multidões  |  \n",
        "| 9. | montante | [montadoras, montadora, montado, montante]  |  montante |\n",
        "| 10. | leit | [leite, leitura, leituras]  |  leitura  |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Falsos Negativos Encontrados**:\n",
        "\n",
        "|id |  stem_token | tokens  |  wrong_stem_token  |    wrong_token  |\n",
        "| :---: | :---: |  :---:  |   :---:  |     :---:  |\n",
        "| 1. | aproveit | [aproveita, aproveitamento, aproveitaram]  |  aprove  |    aproveitar  |\n",
        "| 2. | aposentad | [aposentadoria]  |  aposent  |    aposentado  |\n",
        "| 3. | arrecad | [arrecadados, arrecadação, arrecadado, arrecadar]  |  arrec  |    arrecada  |\n",
        "| 4. | assegur | [assegurar]  |  asseg  |    assegura  |\n",
        "| 5. | assessor | [assessora, assessor, assessores]  |  assess  |    assessoria  |\n",
        "| 6. | deliber | [deliberar, deliberações]  |  deliberá-l  |    deliberá-lo  |\n",
        "| 7. | demand | [demanda]  |  demandar-s  |    demandar-se  |\n",
        "| 8. | emocion | [emocionaram]  |  emoc  |   emocional  |\n",
        "| 9. | habilit | [habilitado]  |  habil |    habilitar |\n",
        "| 10. | orçament | [orçamentário]  |  orç |    orçamento  |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}